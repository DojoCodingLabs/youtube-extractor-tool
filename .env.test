# Test Environment Configuration
# Copy this to .env and fill in real values for testing

# LLM Configuration - Choose one
LLM_MODEL=gpt-4o-mini
# OPENAI_API_KEY=sk-your-test-key-here

# Alternative: Use Anthropic
# LLM_MODEL=claude-3-5-haiku-latest  
# ANTHROPIC_API_KEY=your-test-key-here

# Alternative: Use local Ollama (no API key needed)
# LLM_MODEL=ollama/llama3.2:3b

# Test-specific settings
ENABLE_CACHE=true
CACHE_DIR=./.test_cache
DEFAULT_OUTPUT_DIR=./output
DEFAULT_CHUNK_CHARS=2000  # Smaller chunks for faster testing

# Test video processing limits
MAX_CONCURRENT_VIDEOS=1   # Conservative for testing
REPORT_TZ=UTC

# Optional: Whisper for transcript fallback testing
# WHISPER_MODEL=tiny      # Fastest model for testing
# WHISPER_DEVICE=cpu      # Use CPU for consistent test results